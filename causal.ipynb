{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9dd40c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'module.name' from '/home/rtx4090/code/python/current/Iregular/configs/OurModelConfig.py'> OurModelConfig\n",
      "✅ All __pycache__ folders removed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OurModelConfig(classification=False, ablation=0, try_exp=1, ts_var=1, input_size=21, bs=512, lr=0.001, decay=0.0001, loss_func='MSELoss', optim='Adam', epochs=50, patience=10, verbose=50, device='cuda', monitor_metric='MAE', use_amp=False, monitor_reverse=False, path='./data', task='bench201', dataset='weather', predict_target='y', eval_set=True, shuffle=False, scaler_method='minmax', spliter_ratio='7:1:2', sample_method='ours', seq_len=96, pred_len=192, logger='zyx', model='ours', d_model=56, num_layers=3, retrain=True, seed=0, rounds=5, runid=0, debug=False, record=True, hyper_search=False, continue_train=False, data_dropout=0.3, att_method='self', num_heads=4, att_bias=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment Settings, logger, plotter\n",
    "from utils.exp_logger import Logger\n",
    "from utils.exp_metrics_plotter import MetricsPlotter\n",
    "from utils.utils import set_settings\n",
    "from utils.exp_config import get_config\n",
    "config = get_config('OurModelConfig')\n",
    "set_settings(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55097f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.thresh = 0.3\n",
    "config.pc_alpha = 0.05\n",
    "config.causal_lr = 0.05\n",
    "config.pre_gate = 0.80\n",
    "config.sub_method = 'DirectLiNGAM'\n",
    "config.golem_epoch = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfc7844",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff37514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 21)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from castle.algorithms import ICALiNGAM\n",
    "from castle.algorithms import DirectLiNGAM\n",
    "from castle.algorithms import PC\n",
    "from castle.algorithms import Notears\n",
    "from castle.algorithms import GraNDAG\n",
    "from castle.algorithms import GOLEM\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np \n",
    "import time\n",
    "\n",
    "from models.hcd import HCD\n",
    "from models.sada import SADA\n",
    "\n",
    "\n",
    "def get_causal_matrix(data, method, config):\n",
    "    data = data.astype(np.float32)\n",
    "    data = StandardScaler().fit_transform(data)\n",
    "    start = time.time()\n",
    "    if method == 'PC':\n",
    "        model = PC(alpha=config.pc_alpha)\n",
    "    if method == 'ICALiNGAM':\n",
    "        model = ICALiNGAM(thresh=config.thresh)\n",
    "    if method == 'DirectLiNGAM':\n",
    "        model = DirectLiNGAM(thresh=config.thresh)\n",
    "        \n",
    "    if method == 'Notears':\n",
    "        model = Notears(w_threshold=config.thresh)\n",
    "    if method == 'GraNDAG':\n",
    "        model = GraNDAG(input_dim=data.shape[1], device_type='gpu')\n",
    "    if method == 'GOLEM':\n",
    "        model = GOLEM(num_iter=config.golem_epoch, graph_thres=config.thresh, device_type='gpu', learning_rate=config.lr)\n",
    "        \n",
    "    if method == 'SADA':\n",
    "        model = SADA(theta=10, alpha=0.05, k=10, max_cond=3, sub_method=\"pc\", thresh=config.thresh, pc_alpha=config.pc_alpha)\n",
    "    if method == 'HCD':\n",
    "        model = HCD(pre_gate=config.pre_gate, thresh=config.thresh, method=config.sub_method)\n",
    "        \n",
    "    model.learn(data)\n",
    "    end=time.time()\n",
    "    execute_time = end - start\n",
    "    print(f\"Method {method} Done. Execution time = {execute_time}\")\n",
    "    return model.causal_matrix, execute_time\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "df = pd.read_csv('data/timeseries/weather.csv').to_numpy()[:, 1:].astype(np.float32)\n",
    "df = df[:500]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5848daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method SADA Done. Execution time = 0.289902925491333\n",
      "Edges: 29\n"
     ]
    }
   ],
   "source": [
    "causal_matrix, execute_time = get_causal_matrix(df, 'SADA', config)\n",
    "print(\"Edges:\", int((causal_matrix > 0).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e40f6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method PC Done. Execution time = 0.22409319877624512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rtx4090/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 7 iterations, alpha=6.504e-07, previous alpha=6.440e-07, with an active set of 4 regressors.\n",
      "  warnings.warn(\n",
      "/home/rtx4090/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=3.052e-06, previous alpha=2.895e-06, with an active set of 5 regressors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method ICALiNGAM Done. Execution time = 0.25539255142211914\n",
      "Method DirectLiNGAM Done. Execution time = 0.5398201942443848\n",
      "Method SADA Done. Execution time = 0.3375735282897949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 15:20:36,223 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:195] - INFO: [start]: n=500, d=21, iter_=100, h_=1e-08, rho_=1e+16\n",
      "2025-10-23 15:20:36,364 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 0] h=3.223e-01, loss=10.500, rho=1.0e+00\n",
      "2025-10-23 15:20:36,402 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 1] h=2.193e-01, loss=3.577, rho=1.0e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method HCD Done. Execution time = 0.9973239898681641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 15:20:36,433 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 1] h=9.806e-02, loss=4.045, rho=1.0e+01\n",
      "2025-10-23 15:20:36,504 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 1] h=3.592e-02, loss=8.720, rho=1.0e+02\n",
      "2025-10-23 15:20:36,540 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 2] h=2.179e-02, loss=3.904, rho=1.0e+02\n",
      "2025-10-23 15:20:36,604 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 2] h=7.420e-03, loss=4.485, rho=1.0e+03\n",
      "2025-10-23 15:20:36,639 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 3] h=4.236e-03, loss=3.995, rho=1.0e+03\n",
      "2025-10-23 15:20:36,685 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 3] h=1.559e-03, loss=4.242, rho=1.0e+04\n",
      "2025-10-23 15:20:36,719 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 4] h=9.371e-04, loss=4.032, rho=1.0e+04\n",
      "2025-10-23 15:20:36,767 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 4] h=3.815e-04, loss=4.141, rho=1.0e+05\n",
      "2025-10-23 15:20:36,831 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 5] h=2.457e-04, loss=4.055, rho=1.0e+05\n",
      "2025-10-23 15:20:36,933 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 5] h=1.049e-04, loss=4.121, rho=1.0e+06\n",
      "2025-10-23 15:20:37,081 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 5] h=3.460e-05, loss=4.776, rho=1.0e+07\n",
      "2025-10-23 15:20:37,259 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 6] h=2.125e-05, loss=4.088, rho=1.0e+07\n",
      "2025-10-23 15:20:37,559 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 6] h=9.679e-06, loss=4.142, rho=1.0e+08\n",
      "2025-10-23 15:20:37,905 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 6] h=4.218e-06, loss=4.681, rho=1.0e+09\n",
      "2025-10-23 15:20:38,010 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 7] h=3.116e-06, loss=4.126, rho=1.0e+09\n",
      "2025-10-23 15:20:38,271 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 7] h=1.635e-06, loss=4.206, rho=1.0e+10\n",
      "2025-10-23 15:20:39,341 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 7] h=5.772e-07, loss=5.007, rho=1.0e+11\n",
      "2025-10-23 15:20:40,040 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 8] h=3.522e-07, loss=4.213, rho=1.0e+11\n",
      "2025-10-23 15:20:41,267 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 8] h=1.524e-07, loss=4.363, rho=1.0e+12\n",
      "2025-10-23 15:20:43,344 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 8] h=5.630e-08, loss=5.863, rho=1.0e+13\n",
      "2025-10-23 15:20:43,753 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 9] h=3.835e-08, loss=4.290, rho=1.0e+13\n",
      "2025-10-23 15:20:45,012 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 9] h=1.750e-08, loss=4.433, rho=1.0e+14\n",
      "2025-10-23 15:20:46,900 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:206] - INFO: [iter 9] h=6.694e-09, loss=5.859, rho=1.0e+15\n",
      "2025-10-23 15:20:46,900 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/linear.py[line:222] - INFO: FINISHED\n",
      "2025-10-23 15:20:46,902 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/gran_dag/torch/gran_dag.py[line:269] - INFO: GPU is available.\n",
      "/home/rtx4090/anaconda3/lib/python3.12/site-packages/torch/__init__.py:955: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538455419/work/torch/csrc/tensor/python_tensor.cpp:432.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method Notears Done. Execution time = 10.677897214889526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations: 100%|██████████| 10000/10000 [01:11<00:00, 139.70it/s]\n",
      "2025-10-23 15:21:58,621 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/torch/golem.py[line:119] - INFO: GPU is available.\n",
      "2025-10-23 15:21:58,622 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/torch/golem.py[line:190] - INFO: Started training for 5000 iterations.\n",
      "2025-10-23 15:21:58,652 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/torch/golem.py[line:203] - INFO: [Iter 0] score=97.221, likelihood=97.221, h=0.0e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method GraNDAG Done. Execution time = 71.71925854682922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 15:22:05,386 - /home/rtx4090/anaconda3/lib/python3.12/site-packages/castle/algorithms/gradient/notears/torch/golem.py[line:203] - INFO: [Iter 5000] score=73.926, likelihood=70.683, h=1.8e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method GOLEM Done. Execution time = 6.766377925872803\n"
     ]
    }
   ],
   "source": [
    "def run_all_methods(data, config):\n",
    "    \"\"\"\n",
    "    data: np.ndarray [n, d]\n",
    "    config: 超参数配置对象\n",
    "    返回: {method_name: {\"causal_matrix\": W, \"time\": t}}\n",
    "    \"\"\"\n",
    "    methods = [\n",
    "        'PC', 'ICALiNGAM', 'DirectLiNGAM',\n",
    "        'SADA', 'HCD', \n",
    "        'Notears', 'GraNDAG', 'GOLEM',\n",
    "    ]\n",
    "    results = {}\n",
    "    for m in methods:   # 按字典序排序\n",
    "        try:\n",
    "            W, t = get_causal_matrix(data, m, config)\n",
    "            results[m] = {\"causal_matrix\": W, \"time\": t}\n",
    "        except Exception as e:\n",
    "            results[m] = {\"error\": str(e)}\n",
    "    return results\n",
    "\n",
    "results = run_all_methods(df, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b6a3365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== PC ==========\n",
      "Time: 0.22409319877624512\n",
      "Edges: 36\n",
      "========== ICALiNGAM ==========\n",
      "Time: 0.25539255142211914\n",
      "Edges: 99\n",
      "========== DirectLiNGAM ==========\n",
      "Time: 0.5398201942443848\n",
      "Edges: 52\n",
      "========== SADA ==========\n",
      "Time: 0.3375735282897949\n",
      "Edges: 29\n",
      "========== HCD ==========\n",
      "Time: 0.9973239898681641\n",
      "Edges: 78\n",
      "========== Notears ==========\n",
      "Time: 10.677897214889526\n",
      "Edges: 20\n",
      "========== GraNDAG ==========\n",
      "Time: 71.71925854682922\n",
      "Edges: 12\n",
      "========== GOLEM ==========\n",
      "Time: 6.766377925872803\n",
      "Edges: 69\n"
     ]
    }
   ],
   "source": [
    "for k, v in results.items():\n",
    "    print(\"==========\" , k , \"==========\")\n",
    "    if \"error\" in v:\n",
    "        print(\"Error:\", v[\"error\"])\n",
    "    else:\n",
    "        print(\"Time:\", v[\"time\"])\n",
    "        print(\"Edges:\", int((v[\"causal_matrix\"] > 0).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于分而治之算法\n",
    "causal_matrix, execute_time = get_causal_matrix(df, 'HCD', config)\n",
    "causal_matrix, execute_time = get_causal_matrix(df, 'SADA', config)\n",
    "# 基于统计学算法的\n",
    "causal_matrix, execute_time = get_causal_matrix(df, 'PC', config)\n",
    "causal_matrix, execute_time = get_causal_matrix(df, 'ICALiNGAM', config)\n",
    "causal_matrix, execute_time = get_causal_matrix(df, 'DirectLiNGAM', config)\n",
    "# 基于训练的\n",
    "causal_matrix, execute_time = get_causal_matrix(df, 'Notears', config)\n",
    "causal_matrix, execute_time = get_causal_matrix(df, 'GraNDAG', config)\n",
    "causal_matrix, execute_time = get_causal_matrix(df, 'GOLEM', config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e32f4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
