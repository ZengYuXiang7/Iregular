{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dceba3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52696, 22)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "df = pd.read_csv('./data/timeseries/weather.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5953ab83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36600/36600 [00:00<00:00, 56640.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([51648271, 3]), 73785600)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import *\n",
    "train_len, val_len, test_len = 36600, 4982, 10253\n",
    "data = torch.rand(train_len, 96, 21)\n",
    "drop_out = 0.3\n",
    "\n",
    "random_matrix = torch.ones(train_len, 96, 21)\n",
    "# random_matrix = torch.zeros(self.data['x'], config.seq_len, enc_in)\n",
    "for i in trange(train_len):\n",
    "    mask = torch.rand(96, 21)\n",
    "    mask[mask <= drop_out] = 0\n",
    "    random_matrix[i] = mask\n",
    "data = data * random_matrix\n",
    "data.nonzero().shape, 36600 * 96 * 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "def read_ushcn_file(path: str) -> pd.DataFrame:\n",
    "    records = []\n",
    "    with gzip.open(path, 'rt') as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            station_id = line[0:6].strip()\n",
    "            element = int(line[6:7])\n",
    "            year = int(line[7:11])\n",
    "\n",
    "            values, flags = {}, {}\n",
    "            for i in range(13):  # 12个月 + 年值\n",
    "                start_val = 12 + i * 7\n",
    "                end_val = start_val + 5\n",
    "                val_str = line[start_val:end_val].strip()\n",
    "                flag_str = line[end_val:end_val+1].strip()\n",
    "\n",
    "                val = None if val_str in [\"\", \"-9999\"] else int(val_str)\n",
    "                flag = flag_str if flag_str else None\n",
    "\n",
    "                if i < 12:\n",
    "                    values[f\"VALUE{i+1}\"] = val\n",
    "                    flags[f\"FLAG{i+1}\"] = flag\n",
    "                else:\n",
    "                    values[\"VALUE13\"] = val\n",
    "                    flags[\"FLAG13\"] = flag\n",
    "\n",
    "            records.append({\n",
    "                \"STATION_ID\": station_id,\n",
    "                \"ELEMENT\": element,\n",
    "                \"YEAR\": year,\n",
    "                **values,\n",
    "                **flags\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# 示例\n",
    "df = read_ushcn_file(\"./data/iregular/USHCN/ushcn_v2_monthly/9641C_201112_F52.pcp.gz\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7592ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "data = torch.load('data/iregular/USHCN/ushcn.pt', map_location='cpu', weights_only=True)\n",
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687cb90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][0], data[0][1].shape, data[0][2].shape, data[0][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812bd8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\"  Time indices shape: {data[i][0]}\")\n",
    "    print(f\"  Node indices shape: {data[i][1].shape}\")\n",
    "    # print(f\"  Static features shape: {data[i][2].shape}\")\n",
    "    # print(f\"  Mask shape: {data[i][3].shape}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c003ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser('IMTS Forecasting')\n",
    "\n",
    "parser.add_argument('--state', type=str, default='def')\n",
    "parser.add_argument('-n',  type=int, default=int(1e8), help=\"Size of the dataset\")\n",
    "parser.add_argument('--hop', type=int, default=1, help=\"hops in GNN\")\n",
    "parser.add_argument('--nhead', type=int, default=1, help=\"heads in Transformer\")\n",
    "parser.add_argument('--tf_layer', type=int, default=1, help=\"# of layer in Transformer\")\n",
    "parser.add_argument('--nlayer', type=int, default=1, help=\"# of layer in TSmodel\")\n",
    "parser.add_argument('--epoch', type=int, default=1000, help=\"training epoches\")\n",
    "parser.add_argument('--patience', type=int, default=10, help=\"patience for early stop\")\n",
    "parser.add_argument('--history', type=int, default=24, help=\"number of hours (months for ushcn and ms for activity) as historical window\")\n",
    "parser.add_argument('-ps', '--patch_size', type=float, default=24, help=\"window size for a patch\")\n",
    "parser.add_argument('--stride', type=float, default=24, help=\"period stride for patch sliding\")\n",
    "parser.add_argument('--logmode', type=str, default=\"a\", help='File mode of logging.')\n",
    "\n",
    "parser.add_argument('--lr',  type=float, default=1e-3, help=\"Starting learning rate.\")\n",
    "parser.add_argument('--w_decay', type=float, default=0.0, help=\"weight decay.\")\n",
    "parser.add_argument('-b', '--batch_size', type=int, default=32)\n",
    "\n",
    "parser.add_argument('--save', type=str, default='experiments/', help=\"Path for save checkpoints\")\n",
    "parser.add_argument('--load', type=str, default=None, help=\"ID of the experiment to load for evaluation. If None, run a new experiment.\")\n",
    "parser.add_argument('--seed', type=int, default=1, help=\"Random seed\")\n",
    "parser.add_argument('--dataset', type=str, default='physionet', help=\"Dataset to load. Available: physionet, mimic, ushcn\")\n",
    "\n",
    "# value 0 means using original time granularity, Value 1 means quantization by 1 hour, \n",
    "# value 0.1 means quantization by 0.1 hour = 6 min, value 0.016 means quantization by 0.016 hour = 1 min\n",
    "parser.add_argument('--quantization', type=float, default=0.0, help=\"Quantization on the physionet dataset.\")\n",
    "parser.add_argument('--model', type=str, default='tPatchGNN', help=\"Model name\")\n",
    "parser.add_argument('--outlayer', type=str, default='Linear', help=\"Model name\")\n",
    "parser.add_argument('-hd', '--hid_dim', type=int, default=64, help=\"Number of units per hidden layer\")\n",
    "parser.add_argument('-td', '--te_dim', type=int, default=10, help=\"Number of units for time encoding\")\n",
    "parser.add_argument('-nd', '--node_dim', type=int, default=10, help=\"Number of units for node vectors\")\n",
    "parser.add_argument('--gpu', type=str, default='0', help='which gpu to use.')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b5286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.n_months = 48 # 48 monthes\n",
    "args.pred_window = 1 # predict future one month\n",
    "\n",
    "def USHCN_time_chunk(data, args, device):\n",
    "\n",
    "\tchunk_data = []\n",
    "\n",
    "\tfor b, (record_id, tt, vals, mask) in enumerate(data):\n",
    "\t\tfor st in range(0, args.n_months - args.history - args.pred_window + 1, args.pred_window):\n",
    "\t\t\tet = st + args.history + args.pred_window\n",
    "\t\t\tif(et == args.n_months):\n",
    "\t\t\t\tindices = torch.where((tt >= st) & (tt <= et))[0]\n",
    "\t\t\telse:\n",
    "\t\t\t\tindices = torch.where((tt >= st) & (tt < et))[0]\n",
    "\t\t\tt_bias = torch.tensor(st).to(device)\n",
    "\t\t\tchunk_data.append((record_id, tt[indices]-t_bias, vals[indices], mask[indices], t_bias))\n",
    "\n",
    "\treturn chunk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4056c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_data = USHCN_time_chunk(data, args, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab62a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunk_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunk_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0324e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e9c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_data[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b3807",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_data[5][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e025fdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Time', 'Value_0', 'Value_1', 'Value_2', 'Value_3', 'Value_4',\n",
       "       'Mask_0', 'Mask_1', 'Mask_2', 'Mask_3', 'Mask_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('data/iregular/USHCN/small_chunked_sporadic.csv')\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "754c4227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7ecd04aaf1d0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85afbef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
